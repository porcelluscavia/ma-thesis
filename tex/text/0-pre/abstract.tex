\begin{abstract} 
This thesis presents an exploration of explainable machine learning in the context of a traditional linguistic area (dialect classification) and an applied task (sexism detection).
In both tasks, the input features deemed especially relevant for the classification form meaningful groups that fit in with previous research on the topic, although not all such features are easy to understand or provide plausible explanations.
In the case of dialect classification, some important features show that the model also learned patterns that are not typically presented by dialectologists.
For both case studies, I use LIME \citep{ribeiro2016lime} to rank features by their importance for the classification.
For the sexism detection task, I additionally examine attention weights, which produce feature rankings that are in many cases similar to the LIME results but that are over all worse at showcasing tokens that are especially characteristic of sexist tweets.
\end{abstract}